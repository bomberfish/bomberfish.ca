export const title = "Why it might be a good idea to pull the brakes on AI"
export const description = "My opinions on the current pickle the world finds itself in."
export const image = "/blog-images/ai-dep.gif"
export const tags = ["Opinion", "Rant"]

![The XKCD "Dependencies" panel, with what appears to be a jack of sorts wedged in the middle, causing half of the stack to tilt precariously to the left.](/blog-images/ai-dep.gif)

I'd like to preface this by saying that I am by no means qualified or deeply knowledgeable in the topic at hand. If you came here expecting a nuanced and well-researched take on the current pace of AI development, <u>it's best you turn back **now**</u>. I'm just a moody teenager with a strong opinion and nowhere to voice it. 

And if you were wondering, this post was never touched by clanker hands (tool calls? shoggoth tentacles?) <br/>
What you're reading is 100% human-created.

With all of that out of the way, let's get started.

## Some background

The year is (late) 2025. "Attention Is All You Need" was published 8 years ago, OpenAI released `gpt-3.5-turbo` 3 years ago (despite a year earlier refusing to release GPT-3 due to concerns around misinformation!), and we currently live in an absolute hellscape of an AI race. We're continually getting the new "best model ever" on a weekly basis. Billions are being poured into anything with "AI" in the pitch deck, and if it all goes south, we get a second Great Depression. Not to mention, everyone's racing to build hyperscale datacenters and GPU farms to train these models and do inference with them, which has definitely had quite a few consequences.

And you're telling me we haven't stopped to think for just a minute? Let's just go over a *few* of the adverse effects:

- **Layoffs**: No, this doesn't mean that LLMs can replace people's jobs. It means that managers *think* that they can. 
- **Environmental Impact**: You've heard this one before, but it's still true. Those aforementioned hyperscalers use lots of electricity, and all of that has to come from somewhere. Let's just say, renewables aren't quite our main power source yet, and the noise made from their cooling systems is an absolute nuisance they are to the towns they're built near.
- **Everyone forgets how to think for themselves**: Studies show that making the machine think for you does in fact make you think less. 
- **Misalignment**: If we don't stop and make sure the machine is aligned with human values, we'll end up building Skynet.
- **Misuse out the wazoo**: ...wait. That deserves an entire section of its own!

## How other people are using AI to make the world a worse place

Alright. First of all, let's pick off the easiest thing: fabricated information. As I mentioned before, OpenAI themselves were worried about the proliferation of fake news when GPT-3 was created (that didn't stop them from releasing it anyways!). 

The obvious things are fake news stories, backed up by AI-generated images, video, and audio. But that only scratches the surface. Take, for example, scams. Now, a random fella in Nigeria can fake the voice and face of one of your relatives and demand a ransom. Do you really want that future? Your grandparentsâ€“ hell, even your parents don't stand a chance!

Now, for something a bit more serious. Various private companies (e.g. Palantir, Flock Safety) are using AI-based solutions to enhance their (rather creepy!) surveillance platforms. It's only a matter of time before we slip into the Watch Dogs timeline, and it probably won't be as cool as the games.

Anyway, now that I'm getting a bit tired of writing, let's go over a few common arguments against the slowing of AI development in rapid-fire succession.

## "If we stopped, China would beat us!"

Bullshit. If humanity was able to work out nuclear nonproliferation in the 60s, I can guarantee we can agree to put down the H100s for a few years and work out the ethics of this Pandora's box we've opened and maybe regulate it a bit.

Also, the Cold War is over, ya damn boomer.

## "You're just a luddite!"

For crying out loud, I'm not calling for some kind of Butlerian Jihad against all autocorrect. I said I just wanted to take a short break. 

## "Regulation stifles innovation!"

Yeah, apply the same logic to something like cars. Would it really be a great idea to have every road be an Autobahn with no traffic lights or signs? Hopefully *then* you can understand why putting regulations on AI is a good idea.

## Conclusion

All in all, I really think we should just take a breather, y'know? Figure out if it's really worthwhile to go all in on the tech, and maybe put some rules and regulations in place to tame the beast we've created.

But of course, that'll never happen, because number must go up *now*.